{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import cv2\n","from matplotlib import pyplot as plt\n","\n","# Load an image from disk\n","image = cv2.imread('OIP_3.jpg')\n","\n","# Convert the image from BGR to RGB (OpenCV loads images in BGR format by default)\n","image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","# Check if the image was loaded successfully\n","if image is not None:\n","    # Display the image using Matplotlib\n","    plt.imshow(image_rgb)\n","    plt.axis('off')  # Hide axis\n","    plt.show()\n","else:\n","    print(\"Error: Unable to load the image.\")\n","\n","# Save the image to disk in a different format\n","cv2.imwrite('OIP_3.png', image)\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["X_train shape: (2513, 100, 100, 3)\n","y_train shape: (2513,)\n"]}],"source":["import os\n","import cv2\n","import numpy as np\n","\n","# Function to load and preprocess images\n","def load_images_from_folders(folders):\n","    images = []\n","    labels = []\n","    for class_id, folder in enumerate(folders):\n","        for filename in os.listdir(folder):\n","            img_path = os.path.join(folder, filename)\n","            if img_path.endswith(\".jpg\") or img_path.endswith(\".png\"):\n","                img = cv2.imread(img_path, cv2.IMREAD_COLOR)  # Load image in color (BGR)\n","                if img is not None:\n","                    img = cv2.resize(img, (100, 100))  # Resize image if necessary\n","                    images.append(img)\n","                    labels.append(class_id)  # Assign class label based on subdirectory index\n","    return images, labels\n","\n","# Load images from train dataset\n","train_folders = [\"/workspaces/TRY/DATASET/DATASET/TEST/O\", \"/workspaces/TRY/DATASET/DATASET/TEST/R\"]\n","train_images, train_labels = load_images_from_folders(train_folders)\n","\n","# Convert lists to numpy arrays\n","X_train = np.array(train_images)\n","y_train = np.array(train_labels)\n","\n","# Normalize pixel values to the range [0, 1]\n","X_train = X_train.astype('float32') / 255.0\n","\n","# Print the shapes of the datasets\n","print(\"X_train shape:\", X_train.shape)\n","print(\"y_train shape:\", y_train.shape)\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["X_train shape: (0, 1)\n","y_train shape: (0,)\n","X_test shape: (0, 1)\n","y_test shape: (0,)\n"]}],"source":["import cv2\n","import os\n","import numpy as np\n","\n","# Function to load and preprocess images\n","def load_images_from_folder(folder):\n","    images = []\n","    labels = []\n","    for filename in os.listdir(folder):\n","        img_path = os.path.join(folder, filename)\n","        if img_path.endswith(\".jpg\") or img_path.endswith(\".png\"):\n","            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n","            if img is not None:\n","                img = cv2.resize(img, (100, 100))  # Resize image if necessary\n","                images.append(img)\n","                labels.append(1 if \"cat\" in filename else 0)  # Example: 1 for cat, 0 for non-cat\n","    return images, labels\n","\n","# Load images from train dataset\n","train_folder = \"/workspaces/TRY/DATASET/TRAIN\"\n","train_images, train_labels = load_images_from_folder(train_folder)\n","\n","# Load images from test dataset\n","test_folder = \"/workspaces/TRY/DATASET/TEST\"\n","test_images, test_labels = load_images_from_folder(test_folder)\n","\n","# Convert lists to numpy arrays\n","X_train = np.array(train_images)\n","y_train = np.array(train_labels)\n","X_test = np.array(test_images)\n","y_test = np.array(test_labels)\n","\n","# Normalize pixel values to the range [0, 1]\n","X_train = X_train.astype('float32') / 255.0\n","X_test = X_test.astype('float32') / 255.0\n","\n","# Reshape the input data to be in the form of (samples, height, width, channels)\n","X_train = np.expand_dims(X_train, axis=-1)\n","X_test = np.expand_dims(X_test, axis=-1)\n","\n","# Print the shapes of the datasets\n","print(\"X_train shape:\", X_train.shape)\n","print(\"y_train shape:\", y_train.shape)\n","print(\"X_test shape:\", X_test.shape)\n","print(\"y_test shape:\", y_test.shape)\n","\n","# Now, you can use these datasets to train and test your machine learning model.\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["X_train shape: (0, 1)\n","y_train shape: (0,)\n","X_test shape: (0, 1)\n","y_test shape: (0,)\n"]}],"source":["import cv2\n","import os\n","import numpy as np\n","\n","# Function to load and preprocess images\n","def load_images_from_folder(folder):\n","    images = []\n","    labels = []\n","    for filename in os.listdir(folder):\n","        img_path = os.path.join(folder, filename)\n","        if img_path.endswith(\".jpg\") or img_path.endswith(\".png\"):\n","            img = cv2.imread(img_path, cv2.IMREAD_COLOR)  # Load image in color (BGR)\n","            if img is not None:\n","                img = cv2.resize(img, (100, 100))  # Resize image if necessary\n","                images.append(img)\n","                labels.append(1 if \"R\" in filename else 0)  # 1 for \"R\" (recycle), 0 for \"O\" (organic)\n","    return images, labels\n","\n","# Load images from train dataset\n","train_folder = \"/workspaces/TRY/DATASET/DATASET/TRAIN\"\n","train_images, train_labels = load_images_from_folder(train_folder)\n","\n","# Load images from test dataset\n","test_folder = \"/workspaces/TRY/DATASET/DATASET/TEST\"\n","test_images, test_labels = load_images_from_folder(test_folder)\n","\n","# Convert lists to numpy arrays\n","X_train = np.array(train_images)\n","y_train = np.array(train_labels)\n","X_test = np.array(test_images)\n","y_test = np.array(test_labels)\n","\n","# Normalize pixel values to the range [0, 1]\n","X_train = X_train.astype('float32') / 255.0\n","X_test = X_test.astype('float32') / 255.0\n","\n","# Reshape the input data to be in the form of (samples, height, width, channels)\n","X_train = np.expand_dims(X_train, axis=-1)\n","X_test = np.expand_dims(X_test, axis=-1)\n","\n","# Print the shapes of the datasets\n","print(\"X_train shape:\", X_train.shape)\n","print(\"y_train shape:\", y_train.shape)\n","print(\"X_test shape:\", X_test.shape)\n","print(\"y_test shape:\", y_test.shape)\n","\n","# Now, you can use these datasets to train and test your machine learning model.\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-04-26 21:13:22.767708: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n","2024-04-26 21:13:22.771123: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n","2024-04-26 21:13:22.815341: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-04-26 21:13:26.734668: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/home/codespace/.python/current/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","2024-04-26 21:13:32.226817: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 241200000 exceeds 10% of free system memory.\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 316ms/step - accuracy: 0.6931 - loss: 0.6618 - val_accuracy: 0.8926 - val_loss: 0.2901\n","Epoch 2/10\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 319ms/step - accuracy: 0.8942 - loss: 0.2609 - val_accuracy: 0.8827 - val_loss: 0.3206\n","Epoch 3/10\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 332ms/step - accuracy: 0.9075 - loss: 0.2419 - val_accuracy: 0.9145 - val_loss: 0.2408\n","Epoch 4/10\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 353ms/step - accuracy: 0.9203 - loss: 0.2137 - val_accuracy: 0.9264 - val_loss: 0.1983\n","Epoch 5/10\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 303ms/step - accuracy: 0.9180 - loss: 0.1853 - val_accuracy: 0.9145 - val_loss: 0.2103\n","Epoch 6/10\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 340ms/step - accuracy: 0.9439 - loss: 0.1577 - val_accuracy: 0.9046 - val_loss: 0.2418\n","Epoch 7/10\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 303ms/step - accuracy: 0.9527 - loss: 0.1320 - val_accuracy: 0.9145 - val_loss: 0.2390\n","Epoch 8/10\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 344ms/step - accuracy: 0.9605 - loss: 0.1180 - val_accuracy: 0.9264 - val_loss: 0.2171\n","Epoch 9/10\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 354ms/step - accuracy: 0.9636 - loss: 0.0930 - val_accuracy: 0.9046 - val_loss: 0.2922\n","Epoch 10/10\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 301ms/step - accuracy: 0.9657 - loss: 0.0963 - val_accuracy: 0.9165 - val_loss: 0.3097\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 169ms/step - accuracy: 0.9200 - loss: 0.3215\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"name":"stdout","output_type":"stream","text":["Test accuracy: 0.916500985622406\n"]}],"source":["import os\n","import cv2\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras import layers, models\n","\n","# Function to load and preprocess images\n","def load_images_from_folders(folders):\n","    images = []\n","    labels = []\n","    for class_id, folder in enumerate(folders):\n","        for filename in os.listdir(folder):\n","            img_path = os.path.join(folder, filename)\n","            if img_path.endswith(\".jpg\") or img_path.endswith(\".png\"):\n","                img = cv2.imread(img_path, cv2.IMREAD_COLOR)  # Load image in color (BGR)\n","                if img is not None:\n","                    img = cv2.resize(img, (100, 100))  # Resize image if necessary\n","                    images.append(img)\n","                    labels.append(class_id)  # Assign class label based on subdirectory index\n","    return images, labels\n","\n","# Load images from train dataset\n","train_folders = [\"/workspaces/TRY/DATASET/DATASET/TEST/O\", \"/workspaces/TRY/DATASET/DATASET/TEST/R\"]\n","train_images, train_labels = load_images_from_folders(train_folders)\n","\n","# Convert lists to numpy arrays\n","X_train = np.array(train_images)\n","y_train = np.array(train_labels)\n","\n","# Normalize pixel values to the range [0, 1]\n","X_train = X_train.astype('float32') / 255.0\n","\n","# Split the data into training and testing datasets\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n","\n","# Define the CNN model architecture\n","model = models.Sequential([\n","    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)),\n","    layers.MaxPooling2D((2, 2)),\n","    layers.Conv2D(64, (3, 3), activation='relu'),\n","    layers.MaxPooling2D((2, 2)),\n","    layers.Conv2D(64, (3, 3), activation='relu'),\n","    layers.Flatten(),\n","    layers.Dense(64, activation='relu'),\n","    layers.Dense(1, activation='sigmoid')\n","])\n","\n","# Compile the model\n","model.compile(optimizer='adam',\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","\n","# Train the model\n","history = model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n","\n","# Evaluate the model on the test set\n","test_loss, test_acc = model.evaluate(X_val, y_val)\n","print('Test accuracy:', test_acc)\n","# Save the trained model\n","model.save(\"model.h5\")\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n","Predicted class: Organic\n"]}],"source":["from tensorflow.keras.models import load_model\n","\n","# Load the trained model\n","model = load_model('/workspaces/TRY/model.h5')  # Assuming the model is saved as an HDF5 file\n","\n","# Path to the image you want to classify\n","image_path = '/workspaces/TRY/image.jpg'\n","\n","# Preprocess the image (you can reuse the preprocess_image function defined earlier)\n","image = preprocess_image(image_path)\n","\n","# Predict the class probabilities\n","probabilities = model.predict(image)\n","\n","# Classify the image based on thresholding (similar to the previous code)\n","threshold = 0.5  # Adjust the threshold as needed\n","if probabilities[0][0] > threshold:\n","    print(\"Predicted class: Recyclable\")\n","else:\n","    print(\"Predicted class: Organic\")\n","\n"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step\n","Predicted class: Organic\n"]}],"source":["from tensorflow.keras.models import load_model\n","\n","# Load the trained model\n","model = load_model('/workspaces/TRY/model.h5')  # Assuming the model is saved as an HDF5 file\n","\n","# Path to the image you want to classify\n","image_path = '/workspaces/TRY/image2.jpg'\n","\n","# Preprocess the image (you can reuse the preprocess_image function defined earlier)\n","image = preprocess_image(image_path)\n","\n","# Predict the class probabilities\n","probabilities = model.predict(image)\n","\n","# Classify the image based on thresholding (similar to the previous code)\n","threshold = 0.5  # Adjust the threshold as needed\n","if probabilities[0][0] > threshold:\n","    print(\"Predicted class: Recyclable\")\n","else:\n","    print(\"Predicted class: Organic\")\n","\n"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n","Predicted class: Recyclable\n"]}],"source":["from tensorflow.keras.models import load_model\n","\n","# Load the trained model\n","model = load_model('/workspaces/TRY/model.h5')  # Assuming the model is saved as an HDF5 file\n","\n","# Path to the image you want to classify\n","image_path = '/workspaces/TRY/image3.jpg'\n","\n","# Preprocess the image (you can reuse the preprocess_image function defined earlier)\n","image = preprocess_image(image_path)\n","\n","# Predict the class probabilities\n","probabilities = model.predict(image)\n","\n","# Classify the image based on thresholding (similar to the previous code)\n","threshold = 0.5  # Adjust the threshold as needed\n","if probabilities[0][0] > threshold:\n","    print(\"Predicted class: Recyclable\")\n","else:\n","    print(\"Predicted class: Organic\")\n","\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":2}
